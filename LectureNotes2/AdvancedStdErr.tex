\documentclass[english,xcolor=dvipsnames]{beamer}
% load package with ``framed'' and ``numbered'' option.
\usepackage[autolinebreaks,useliterate]{mcode}
\usepackage[orientation=landscape,size=custom,width=16,height=9,scale=0.48,debug]{beamerposter}
\usepackage[T1]{fontenc}
\usepackage[latin9]{inputenc}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{bookmark}
\usepackage{verbatim}
\usepackage{graphics,graphicx}
\usepackage{pstricks,pst-node,pst-tree}
\usefonttheme{serif}
\usepackage{palatino}
%\usepackage[margin=.5cm]{geometry}

\definecolor{dgreen}{rgb}{0.,0.6,0.}
\definecolor{forest}{RGB}{34.,139.,34.}
\definecolor{byublue}{RGB}{0.,30.,76.}
\definecolor{dukeblue}{RGB}{0.,0.,156.}
%\usetheme{Ilmenau}
\usetheme{Warsaw}
\usecolortheme[named=dukeblue]{structure}
%\usecolortheme[named=RawSienna]{structure}
%\usecolortheme[named=byublue]{structure}
\setbeamertemplate{navigation symbols}{}
\setbeamertemplate{footline}{}
\setbeamercovered{transparent}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% NOTE: With Ilmenau style, to get the bullets %
% looking right, do one section and one sub-   %
% section for each set of bullets              %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
\begin{frame}
\title{Inference in Complex Models}
\author{
	Tyler Ransom\\
	\emph{Duke University}\\
%    \today \\
%    \vspace{10cm}
}
\titlepage
\end{frame}

\begin{frame}{Outline}
\begin{itemize}
	\item Review inference
	\item Talk about clustering
	\item Talk about bootstrapping
\end{itemize}
\end{frame}

\begin{frame}{Why all the fuss over standard errors?}
\begin{itemize}
	\item Empiricists are in the business of estimating models and assigning meaning to those model estimates
	\item Coupled with point estimates, standard errors are the most crucial piece of an empiricist’s findings
	\item If the standard errors are wrong, then the results will be wrong, too, because false inferences will be made
	\item This is why so much energy is spent deriving correct standard errors under a variety of assumptions (e.g. Hayashi’s textbook)
\end{itemize}
\end{frame}

\begin{frame}{Standard errors}
Economists prefer to have models with parameter estimates that are \emph{consistent} and \emph{asymptotically normal}, i.e.\\
\begin{equation*}
\sqrt{n}\left(\hat{\beta}-\beta\right) \overset{d}{\rightarrow} N\left(0,\textrm{Avar}\right)
\end{equation*}
(Hayashi, p. 113)
\begin{itemize}
	\item We want to know the variance of our parameter estimates so that we can tell whether or not we got a lucky draw, or if they are actually different from some number (typically zero) 
	\item The standard errors of the $\hat{\beta}$ vector are embedded in the $\widehat{\textrm{Avar}}$ matrix (our estimate of the true $\textrm{Avar}$ matrix)
	\item In the next few slides, we'll go over what the formula is for $\widehat{\textrm{Avar}}$ in more advanced econometric models
\end{itemize}
\end{frame}

\begin{frame}{Corrected standard errors in clustered models}
Suppose we want to estimate standard errors for models in which there are multiple dimensions of agents
\begin{itemize}
	\item e.g. in development, we might have data on individuals in families, across villages, and across countries
	\item We want to get ``correct'' standard errors for the estimates of our models, and we know that there is some amount of correlation (i.e. heteroskedasticity) within families, villages, and countries
	\item By ``correct'' we mean ``consistent in the presence of heteroskedasticity''
\end{itemize}
\end{frame}

\begin{frame}{Other examples of clustering}
IO:
\begin{itemize}
	\item Car data might be classified by vehicle class (e.g. sedan), make (e.g. Ford), and country of origin (i.e. Mitsubishi is different than Toyota, but both come from Japan)
\end{itemize}
Health:
\begin{itemize}
	\item Data on patients for a specific doctor and across hospitals for a similarly specialized doctor (i.e. patients for Doctor X, who is an orthopedic surgeon at Hospital Y; and patients for Doctor Z who is an orthopedic surgeon at hospital W)
\end{itemize}
Education:
\begin{itemize}
	\item Test scores for students in a certain grade, across teachers, across schools in the same district
\end{itemize}
Labor:
\begin{itemize}
	\item Workers in a specific occupation across different firms in different cities
\end{itemize}
\end{frame}


\begin{frame}{Robust clustered standard errors for GMM models}
The formula for robust clustered standard errors is
\[
\widehat{\textrm{Avar}}=\left(\mathbf{X^{\prime}X}\left(\sum_{j=1}^{N_{c}}u_{j}^{\prime}u_{j}\right)^{-1}\mathbf{X^{\prime}X}\right)^{-1}
\]
where
\[
u_{j} = \sum_{i \in j} \varepsilon_{i}\mathbf{x}_{i}
\]
and $N_{c}$ is the number of clusters. When each cluster has just one element, this formula collapses to the ``robust'' variance matrix [next slide]
\end{frame}

\begin{frame}{Robust standard errors for GMM models}
Stata's \texttt{robust} option produces the following Avar matrix:
\[
\widehat{\textrm{Avar}}=\left(\mathbf{X^{\prime}X}\left(\mathbf{X^{\prime}BX}\right)^{-1}\mathbf{X^{\prime}X}\right)^{-1}
\]
where
\begin{itemize}
	\item $\mathbf{X}$ is a matrix of regressors
	\item $\mathbf{B}_{i,i} = \left(y_{i}-x_{i}\hat{\beta}\right)^{2}$ 
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Cluster vs. Robust}
When should I use cluster-corrected standard errors, and when should I use robust standard errors?
\begin{itemize}
	\item If you have any sort of cross-unit correlation (i.e. panel data for people over time, cross sectional data for people over space), you should use cluster-corrected standard errors
	\item The formula collapses to the regular robust formula if there is no clustering
	\item If using fixed effects, cluster at the same level as your fixed effects
	\item If all else fails, you can always bootstrap
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Standard errors for other models}
\begin{itemize}
	\item All classical econometric models can be considered as either GMM or MLE. (Furthermore, GMM and MLE are asymptotically equivalent in some situations)
	\item Most structural econometric models, however, incorporate simulation methods, multiple estimation stages, and/or contraction mapping/fixed point algorithms (in addition to a main GMM/MLE optimization) -- we'll cover these in more detail next class
	\item In these more complex estimation algorithms, it's unclear how the standard errors of the parameter estimates are affected by the use of previous stage estimates and/or simulation draws
	\item The solution to this problem is bootstrapping, which we will cover today
\end{itemize}
\end{frame}

\begin{frame}{Bootstrapping}
\begin{itemize}
	\item Suppose we have a crazy model and we have no idea what the variance of our estimates looks like
	\item The solution to this problem is bootstrapping:
	\item We can recover the variance matrix by inducing randomness into our estimates by sampling observations \emph{with replacement}
	\item We can then repeat this a large number of times and look at the distribution of our estimates
	\item e.g. the 90\% confidence interval will be the 5th and 95th percentiles of our bootstrap distribution
\end{itemize}
\end{frame}

\begin{frame}{Bootstrap Formula}
After running $B$ bootstrap iterations of the program, the bootstrap approximation to the asymptotic variance is calculated according to
\[
\widehat{\textrm{Avar}}=\frac{1}{B-1}\sum_{b=1}^{B}\left[\hat{\theta}_{m}\left(b\right)-\overline{\hat{\theta}}\right]\left[\hat{\theta}_{m}\left(b\right)-\overline{\hat{\theta}}\right]^{\prime}
\]
where $\hat{\theta}_{m}\left(b\right)$ refers to the parameter estimates taken from the subsample of the population (from draw $b$, with replacement), and $\overline{\hat{\theta}}$ is the average parameter estimate, computed over the B bootstrap draws.
\end{frame}

\begin{frame}{Example}
\begin{itemize}
	\item Simple example: Suppose we have a random variable $Z$ which is a function of two other random variables $X$ and $Y$ (i.e. $Z = \frac{X}{Y}$), and we want to estimate $\mathbb{E}[Z]=\mathbb{E}\left[\frac{X}{Y}\right]$, as well as the standard error of our estimate
	\begin{enumerate}
		\item Draw a sample with replacement from the data
		\item Calculate \texttt{mean(Z)}
		\item Repeat $B$ times
		\item Apply the formula from the previous slide
	\end{enumerate}
\item This same process holds for any estimation routine. Just replace step 2 with whatever estimation you're doing.
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Bootstrapping in Matlab}
\begin{itemize}
	\item Matlab has a useful command \texttt{bootstrp} which will automatically sample with replacement and perform bootstrap iterations on any function desired
	\item For more open-ended problems, \texttt{randsample} is a function that will sample data with replacement so users can bootstrap an estimation procedure which may not fit well with \texttt{bootstrp}
	\item Syntax:
\end{itemize}
\begin{lstlisting}
bootstat = bootstrp(nboot,bootfun,d1,...)

y = randsample(population,k,replacement)
\end{lstlisting}
\end{frame}

\end{document}